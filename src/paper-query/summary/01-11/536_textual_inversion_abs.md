# Research Papers Summary

## MoTaDual: Modality-Task Dual Alignment for Enhanced Zero-shot Composed  Image Retrieval

- **ID**: http://arxiv.org/abs/2410.23736v1
- **Published**: 2024-10-31T08:49:05Z
- **Authors**: Haiwen Li, Fei Su, Zhicheng Zhao
- **Categories**: , 

### GPT Summary
This paper presents a novel two-stage framework for zero-shot composed image retrieval (ZS-CIR) that effectively addresses task and modality discrepancies, achieving state-of-the-art results with reduced computational costs. The framework utilizes a textual inversion network and introduces Modality-Task Dual Alignment (MoTaDual) for improved performance across multiple benchmarks.

### New Contributions
The introduction of MoTaDual, which combines large-language models for triplet generation and prompt learning in a multi-modal context, significantly improves the efficiency and accuracy of zero-shot image retrieval while minimizing the need for labeled data.

### Tags
zero-shot learning, composed image retrieval, modality alignment, textual inversion, multi-modal learning, feature extraction, large-language models, prompt learning, task discrepancy, image-text retrieval

### PDF Link
[Link](http://arxiv.org/abs/2410.23736v1)

---

