{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import msclap\n",
    "from msclap import CLAP\n",
    "from tools.project import INPUT_PATH, LOGS_PATH, OUTPUT_PATH, MODELS_PATH\n",
    "from toolz import partition_all, concat\n",
    "import os\n",
    "import torch\n",
    "from audioldm_eval.metrics.fad import FrechetAudioDistance\n",
    "\n",
    "DEVICE = 'cuda'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "clap_model = CLAP(version='2023', use_cuda=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@torch.no_grad\n",
    "def get_dir_embeds(dir_path: str, recalc=True):\n",
    "    dir_name = os.path.basename(dir_path)\n",
    "    cache_path = os.path.join(os.path.dirname(dir_path), f'clap_feature_{dir_name}.pt')\n",
    "    if os.path.exists(cache_path) and not recalc:\n",
    "        return torch.load(cache_path)\n",
    "    files = os.listdir(dir_path)\n",
    "    batches = partition_all(20, files)\n",
    "    res = []\n",
    "\n",
    "    def get_embs(paths):\n",
    "        return clap_model.get_audio_embeddings(paths)\n",
    "\n",
    "    for batch in batches:\n",
    "        res.append(get_embs(os.path.join(dir_path, f) for f in batch))\n",
    "    res = torch.stack(list(concat(res))).detach().cpu()\n",
    "    torch.save(res, cache_path)\n",
    "    return res\n",
    "\n",
    "\n",
    "get_dir_embeds(INPUT_PATH(\"textual-inversion-v3\", 'data', 'valid', '8bit', 'fad')).numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_embeddings = get_dir_embeds(INPUT_PATH(\"textual-inversion-v3\", 'data', 'valid', '8bit', 'fad')).numpy()\n",
    "val_embeddings = get_dir_embeds(OUTPUT_PATH(\"musigen-style\", '8bit', 'temp')).numpy()\n",
    "gen_embeddings = get_dir_embeds(OUTPUT_PATH(\"textual-inversion-v3\", '8bit', 'temp')).numpy()\n",
    "\n",
    "\n",
    "def kncc(train_embeds, val_embeds, gen_embeds, K=5):\n",
    "    index = faiss.IndexFlatIP(train_embeds.shape[-1])\n",
    "    index.add(train_embeddings)\n",
    "    distances_val, indices_val = index.search(val_embeds, K)\n",
    "    distances_gen, indices_gen = index.search(gen_embeds, K)\n",
    "    res = 0.0\n",
    "    for i in range(len(indices_val)):\n",
    "        for j in range(len(indices_gen)):\n",
    "            res += len(set(indices_val[i]).intersection(indices_gen[j])) / K\n",
    "    return res / (i * j)\n",
    "\n",
    "\n",
    "kncc(train_embeddings, val_embeddings, gen_embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def knco(train_embeds, val_embeds, gen_embeds, K=5):\n",
    "    index = faiss.IndexFlatIP(train_embeds.shape[-1])\n",
    "    n = index.ntotal\n",
    "    index.add(gen_embeds)\n",
    "    new_ids = set(np.arange(n, n + gen_embeds.shape[0]))\n",
    "    index.add(train_embeds)\n",
    "    distances_val, indices_val = index.search(val_embeddings, K)\n",
    "    res = 0.0\n",
    "    for ids in indices_val:\n",
    "        res += len(new_ids.intersection(ids)) > 0\n",
    "    return res / len(indices_val)\n",
    "\n",
    "\n",
    "knco(train_embeddings, val_embeddings, gen_embeddings)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "f = FrechetAudioDistance(verbose=True, use_pca=True, use_activation=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fad(reference_path, examples_path):\n",
    "    fd_score = f.score(reference_path, examples_path, recalculate=True)\n",
    "    if isinstance(fd_score, int):\n",
    "        return float(\"inf\")\n",
    "    return list(fd_score.values())[0] * 1e-5\n",
    "\n",
    "\n",
    "fad(OUTPUT_PATH(\"musigen-style\", '8bit', 'temp'), OUTPUT_PATH(\"musigen-style\", 'oim', 'temp'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "@torch.no_grad\n",
    "def clap_sim(description, path):\n",
    "    embeds = get_dir_embeds(path)\n",
    "    text_embeds = clap_model.get_text_embeddings([description]).expand(embeds.shape[0], -1)\n",
    "    return clap_model.compute_similarity(embeds.to('cuda'), text_embeds)[:, 0].mean(dim=0).detach().cpu()\n",
    "\n",
    "\n",
    "clap_sim('Clasical music', OUTPUT_PATH(\"musigen-style\", '8bit', 'temp'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mask = torch.cat([torch.zeros(5), torch.ones(5)]).bool()\n",
    "torch.rand(10, 4, 256)[mask].shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mask"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicgen-WI8jtfXt-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
