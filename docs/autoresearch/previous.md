Agostinelli, Andrea, Timo I. Denk, Zalán Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing
Huang, et al. 2023. “MusicLM: Generating Music from Text.” arXiv. http://arxiv.org/abs/2301.11325.

Burtsev, Mikhail, and Anna Rumshisky. 2021. “Multi-Stream Transformers.” arXiv.
http://arxiv.org/abs/2107.10342.
Caillon, Antoine, and Philippe Esling. 2021. “RAVE: A Variational Autoencoder for Fast and High-Quality
Neural Audio Synthesis.” arXiv. http://arxiv.org/abs/2111.05011.

Copet, Jade, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre
Défossez. 2024. “Simple and Controllable Music Generation.” arXiv. http://arxiv.org/abs/2306.05284.

Défossez, Alexandre, Jade Copet, Gabriel Synnaeve, and Yossi Adi. 2022. “High Fidelity Neural Audio
Compression.” arXiv. http://arxiv.org/abs/2210.13438.

Défossez, Alexandre, Nicolas Usunier, Léon Bottou, and Francis Bach. “Demucs: Deep Extractor for Music
Sources with Extra Unlabeled Data Remixed.” arXiv. http://arxiv.org/abs/1909.01174.

Dhariwal, Prafulla, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, and Ilya Sutskever. n.d.
“Jukebox: A Generative Model for Music.”

Engel, Jesse, Kumar Krishna Agrawal, Shuo Chen, Ishaan Gulrajani, Chris Donahue, and Adam Roberts.
2019. “GANSynth: Adversarial Neural Audio Synthesis.” arXiv. http://arxiv.org/abs/1902.08710.

Engel, Jesse, Lamtharn Hantrakul, Chenjie Gu, and Adam Roberts. 2020. “DDSP: Differentiable Digital Signal
Processing.” arXiv. http://arxiv.org/abs/2001.04643.

Evans, Zach, C. J. Carr, Josiah Taylor, Scott H. Hawley, and Jordi Pons. “Fast Timing-Conditioned Latent
Audio Diffusion.” arXiv. http://arxiv.org/abs/2402.04825.

“Facebookresearch/Encodec: State-of-the-Art Deep Learning Based Audio Codec Supporting Both Mono 24
kHz Audio and Stereo 48 kHz Audio.” n.d. Accessed June 11, https://github.com/facebookresearch/encodec.

Foscarin, Francesco, Katharina Hoedt, Verena Praher, Arthur Flexer, and Gerhard Widmer. 2022. “Concept-
Based Techniques for "Musicologist-Friendly" Explanations in a Deep Music Classifier.” arXiv.
http://arxiv.org/abs/2208.12485.

“Generating Piano Music with Transformer. Magenta.” 2019. September 16,
https://magenta.tensorflow.org/piano-transformer.

Huang, Cheng-Zhi Anna, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Curtis Hawthorne,
Andrew M. Dai, Matthew D. Hoffman, Monica Dinculescu, and Douglas Eck. 2018. “Music Transformer.” arXiv.
http://arxiv.org/abs/1809.04281.



Jonason, Nicolas, Luca Casini, Carl Thomé, and Bob L. T. Sturm. 2023. “Retrieval Augmented Generation of
Symbolic Music with LLMs.” arXiv. http://arxiv.org/abs/2311.10384.


Karras, Tero, Samuli Laine, and Timo Aila. 2019. “A Style-Based Generator Architecture for Generative
Adversarial Networks.” arXiv. http://arxiv.org/abs/1812.04948.

Kim, Jong Wook, Justin Salamon, Peter Li, and Juan Pablo Bello. 2018. “CREPE: A Convolutional
Representation for Pitch Estimation.” arXiv. http://arxiv.org/abs/1802.06182.

Kong, Jungil, Jaehyeon Kim, and Jaekyoung Bae. 2020. “HiFi-GAN: Generative Adversarial Networks for
Efficient and High Fidelity Speech Synthesis.” arXiv. http://arxiv.org/abs/2010.05646.
Koo, Junghyun, Gordon Wichern, Francois G. Germain, Sameer Khurana, and Jonathan Le Roux. 2024.

“SMITIN: Self-Monitored Inference-Time INtervention for Generative Music Transformers.” arXiv.
http://arxiv.org/abs/2404.02252.

Kreuk, Felix, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre Défossez, Jade Copet, Devi Parikh,
Yaniv Taigman, and Yossi Adi. 2023. “AudioGen: Textually Guided Audio Generation.” arXiv.
http://arxiv.org/abs/2209.15352.

Kumar, Kundan, Rithesh Kumar, Thibault de Boissiere, Lucas Gestin, Wei Zhen Teoh, Jose Sotelo, Alexandre
de Brebisson, Yoshua Bengio, and Aaron Courville. 2019. “MelGAN: Generative Adversarial Networks for
Conditional Waveform Synthesis.” arXiv. http://arxiv.org/abs/1910.06711.

Lam, Max W Y, Qiao Tian, Tang Li, Zongyu Yin, Siyuan Feng, Ming Tu, Yuliang Ji, et al. n.d. “Efficient Neural
Music Generation.”

Li, Shuyu, and Yunsick Sung. 2023. “MelodyDiffusion: Chord-Conditioned Melody Generation Using a
Transformer-Based Diffusion Model.” Mathematics 11 (8): 1915. https://doi.org/10.3390/math11081915.

“Machine Learning for Creativity and Design. Machine Learning for Creativity and Design.”
https://neuripscreativityworkshop.github.io/2023/.
“Magenta Demos.” https://magenta.tensorflow.org/demos/web/.
Malik, Iman, and Carl Henrik Ek. 2017. “Neural Translation of Musical Style.” arXiv.
http://arxiv.org/abs/1708.03535.
Manzelli, Rachel, Vijay Thakkar, Ali Siahkamari, and Brian Kulis. 2018. “Conditioning Deep Generative Raw
Audio Models for Structured Automatic Music.” arXiv. http://arxiv.org/abs/1806.09905.

Meade, Nicholas, Nicholas Barreyre, Scott C. Lowe, and Sageev Oore. “Exploring Conditioning for
Generative Music Systems with Human-Interpretable Controls.” arXiv. http://arxiv.org/abs/1907.04352.
Mehri, Soroush, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham Jain, Jose Sotelo, Aaron

Courville, and Yoshua Bengio. 2017. “SampleRNN: An Unconditional End-to-End Neural Audio Generation
Model.” arXiv. http://arxiv.org/abs/1612.07837.

Meseguer-Brocal, Gabriel, and Geoffroy Peeters. 2019. “Conditioned-u-Net: Introducing a Control Mechanism
in the u-Net for Multiple Source Separations,” November. https://doi.org/10.5281/zenodo.3527766.

Müller, Meinard. 2015. Fundamentals of Music Processing: Audio, Analysis, Algorithms, Applications. Cham:
Springer International Publishing. https://doi.org/10.1007/978-3-319-21945-5.

Oord, Aaron van den, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal
Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. “WaveNet: A Generative Model for Raw Audio.”
arXiv. http://arxiv.org/abs/1609.03499.

Oord, Aaron van den, Oriol Vinyals, and Koray Kavukcuoglu. 2018. “Neural Discrete Representation
Learning.” arXiv. http://arxiv.org/abs/1711.00937.

Oore, Sageev, Ian Simon, Sander Dieleman, Douglas Eck, and Karen Simonyan. 2018. “This Time with
Feeling: Learning Expressive Musical Performance.” arXiv. http://arxiv.org/abs/1808.03715.

Perez, Ethan, Florian Strub, Harm de Vries, Vincent Dumoulin, and Aaron Courville. 2017. “FiLM: Visual
Reasoning with a General Conditioning Layer.” arXiv. http://arxiv.org/abs/1709.07871.

“Preface — Digital Signals Theory.” https://brianmcfee.net/dstbook-site/content/intro.html.

robz. 2020. “PerformanceRNN with Note-on Conditioning. Medium.” December 27, 2020.
https://robzz.medium.com/performancernn-with-note-on-conditioning-fac981f82d10.

Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022a. “High-
Resolution Image Synthesis with Latent Diffusion Models.” arXiv. http://arxiv.org/abs/2112.10752.

Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. “U-Net: Convolutional Networks for Biomedical
Image Segmentation.” arXiv. http://arxiv.org/abs/1505.04597.

Shen, Jonathan, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng
Chen, et al. 2018a. “Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions.” arXiv.
http://arxiv.org/abs/1712.05884.

Stoller, Daniel, Sebastian Ewert, and Simon Dixon. 2018. “Wave-u-Net: A Multi-Scale Neural Network for
End-to-End Audio Source Separation.” arXiv. http://arxiv.org/abs/1806.03185.

Xu, Yurui. 2023. “Music Generator Applying Markov Chain and Lagrange Interpolation.” Highlights in Science,
Engineering and Technology 39 (April): 266–73. https://doi.org/10.54097/hset.v39i.6538.

Zeghidour, Neil, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi. 2021.
“SoundStream: An End-to-End Neural Audio Codec.” arXiv. http://arxiv.org/abs/2107.03312.